{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bd9e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1929d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"green_tripdata_2019-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e69eecdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-21 15:17:29</td>\n",
       "      <td>2018-12-21 15:18:57</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:10:16</td>\n",
       "      <td>2019-01-01 00:16:32</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:27:11</td>\n",
       "      <td>2019-01-01 00:31:38</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:46:20</td>\n",
       "      <td>2019-01-01 01:04:54</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:19:06</td>\n",
       "      <td>2019-01-01 00:39:43</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>4.53</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2018-12-21 15:17:29   2018-12-21 15:18:57                  N   \n",
       "1         2  2019-01-01 00:10:16   2019-01-01 00:16:32                  N   \n",
       "2         2  2019-01-01 00:27:11   2019-01-01 00:31:38                  N   \n",
       "3         2  2019-01-01 00:46:20   2019-01-01 01:04:54                  N   \n",
       "4         2  2019-01-01 00:19:06   2019-01-01 00:39:43                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0           1           264           264                5           0.00   \n",
       "1           1            97            49                2           0.86   \n",
       "2           1            49           189                2           0.66   \n",
       "3           1           189            17                2           2.68   \n",
       "4           1            82           258                1           4.53   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0          3.0    0.5      0.5        0.00           0.0        NaN   \n",
       "1          6.0    0.5      0.5        0.00           0.0        NaN   \n",
       "2          4.5    0.5      0.5        0.00           0.0        NaN   \n",
       "3         13.5    0.5      0.5        2.96           0.0        NaN   \n",
       "4         18.0    0.5      0.5        0.00           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3          4.30             2          1   \n",
       "1                    0.3          7.30             2          1   \n",
       "2                    0.3          5.80             1          1   \n",
       "3                    0.3         19.71             1          1   \n",
       "4                    0.3         19.30             2          1   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ebaf44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630918, 20)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9400f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb3e479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = create_engine(\"postgresql://root:root@localhost:5432/ny_taxi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2022363",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv(\"green_tripdata_2019-01.csv\", iterator=True, chunksize=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ee4a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee3876fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8971abcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(0).to_sql(name=\"green_taxi_data\", con=connection, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7909cac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(name=\"green_taxi_data\", con=connection, if_exists=\"append\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b57e8859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n",
      "working on chunk\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(df_iter)\n\u001b[0;32m      3\u001b[0m     df\u001b[39m.\u001b[39mlpep_pickup_datetime \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39mlpep_pickup_datetime)\n\u001b[0;32m      4\u001b[0m     df\u001b[39m.\u001b[39mlpep_dropoff_datetime \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39mlpep_dropoff_datetime)\n",
      "File \u001b[1;32mc:\\Users\\amous\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1186\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1185\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_chunk()\n\u001b[0;32m   1187\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m   1188\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\amous\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1283\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1281\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m     size \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnrows \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_currow)\n\u001b[1;32m-> 1283\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nrows\u001b[39m=\u001b[39;49msize)\n",
      "File \u001b[1;32mc:\\Users\\amous\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1253\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1251\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1253\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[0;32m   1254\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1255\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\amous\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 225\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[0;32m    226\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    227\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mc:\\Users\\amous\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:830\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    df = next(df_iter)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.to_sql(name=\"green_taxi_data\", con=connection, if_exists=\"append\")\n",
    "    print(\"working on chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d652e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "61aea035e6d51e382744cb563cc5f931c93e79651ec7549a09ecf63f1dace857"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
